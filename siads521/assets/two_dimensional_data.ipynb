{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use matplotlib to explore a bit of data. I'm going to focus here on just using the library to build\n",
    "basic charts you are probably already familiar with, and then we'll go on to some more in depth examples of\n",
    "how to do visual exploration of data and data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's bring in matplotlib and turn off the Jupyter display figure magic.\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import set_matplotlib_close\n",
    "set_matplotlib_close(False)\n",
    "\n",
    "# And of course we'll bring in pandas and numpy\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, the data I'm going to use is something called Anscombe's quartet. It's an interesting historic dataset\n",
    "# that was used to demonstrate the important of visual exploration. You can read more about it at wikipedia,\n",
    "# and I've left the code I used to get the data from wikipedia below, but I've commented it out and just\n",
    "# left it for you to see if you're interested.\n",
    "#dataset=pd.read_html(\"https://en.wikipedia.org/wiki/Anscombe%27s_quartet\", skiprows=1)[1]\n",
    "#dataset.columns=[\"x1\",\"y1\",\"x2\",\"y2\",\"x3\",\"y3\",\"x4\",\"y4\"]\n",
    "#dataset.to_csv(\"quartet.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"quartet.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So, the point of Anscombe's quartet is to demonstrate that certain summary statistics might look the same or\n",
    "# nearly the same between different values, but that when we graphically examine them they look quite different.\n",
    "# For instance, let's calculate the mean of each column\n",
    "df.agg(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we see that the mean of the X values is all identical, at 9.0, and that the mean of Y values are all\n",
    "# identical as well, at just a smidge over 7.5 Let's check how correlated the X and Y values are between our\n",
    "# four series of data\n",
    "import scipy.stats as stats\n",
    "\n",
    "for i in range(1,5):\n",
    "    print(\"pearson for {} values is {}\".format(i,stats.pearsonr(df['x{}'.format(i)],df['y{}'.format(i)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok, so even the correlation between the X and Y values across each series is almost identical! And it turns\n",
    "# out that a number of other statistical properties, such as the variance, or the fit of a regression line,\n",
    "# are very similar as well. However, we can often visualize many different kinds of variation at once, and\n",
    "# plotting these points can produce more insight.\n",
    "\n",
    "# Let's check the first series, I'm going to plot this as a scatter plot. To do so we just pass in our X and Y\n",
    "# values as the first two parameters. We can also add a third parameter for the format of the points to use.\n",
    "# This follows a sort of mini programming language, right now I'll just use g. which means a green dot\n",
    "plt.figure()\n",
    "plt.plot(df['x1'],df['y1'],'g.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok, great, a bunch of seemingly random plots. I'm going to plot the next three series as well, and change\n",
    "# the color and the marker type, then rerender the plot. You can check the docs for more details on color\n",
    "# and marker shapes\n",
    "plt.plot(df['x2'],df['y2'],'ro')\n",
    "plt.plot(df['x3'],df['y3'],'b+')\n",
    "plt.plot(df['x4'],df['y4'],'kv')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wow, this looks quite different! Let's change the size of that figure to get a better sense of what has\n",
    "# happened\n",
    "plt.gcf().set_size_inches(12,7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we can see here that the fourth series, the black triangles, have one strong outlier. The red circles,\n",
    "# which were the second series, form a gentle curve. The first series was scattered all around, and the blue\n",
    "# plus signs, which were our third series, are mostly in a horizontal line.\n",
    "\n",
    "# Despite the summary statistics looking very similar, we see there are very much different relationships\n",
    "# between data points, and that's one of the reasons we engage in exploratory data analysis. Now, what does\n",
    "# this mean for a given analysis? That really depends on what the analysis is of. If the x axis was the\n",
    "# predicted grade of a student and the y axis was the amount of time they have spent on a given task, I would\n",
    "# probably come to different conclusions if I were looking at the black triangles (which suggests that time on\n",
    "# task is pretty meaningless, except for that one individual in the upper right) than if I were looking at the\n",
    "# blue plus signs (which suggests that for the most part people benefit from even a small increase in time on\n",
    "# task)\n",
    "\n",
    "# Here are a couple of things I might do to improve this visual if I were looking at it. First I would clear\n",
    "# the axis\n",
    "plt.cla()\n",
    "\n",
    "# Then I would plot my data, here I'll also add a label for my data which is more meaningful\n",
    "plt.plot(df['x4'],df['y4'],'kv', label=\"Subject pool 4\")\n",
    "plt.plot(df['x2'],df['y2'],'b+', label=\"Subject pool 2\")\n",
    "\n",
    "# Then I would add some descriptive text\n",
    "plt.title('Relationship between grades and effort')\n",
    "plt.xlabel(\"Student Grade\")\n",
    "plt.ylabel(\"Effort in minutes\")\n",
    "\n",
    "# Next I might want to make sure the legend is rendered, in this case I'll set its location and some of the\n",
    "# graphical framing for the legend. a Value of 4, which you can read about in the docs, means the legend\n",
    "# should appear in the lower right hand corner\n",
    "plt.legend(loc=4, frameon=False, title='Legend')\n",
    "\n",
    "# Now let's render it\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nice! This plot is looking meaningful and useful. You can see though, there are a lot of different little\n",
    "# options to matplotlib in order to build the kind of plots you might be interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's move on to discuss another kind of two dimensional data plot, the line plot. Now in the matplotlib\n",
    "# scripting interface this is the same thing as a scatter plot, it's just that the points in your series are\n",
    "# connected by lines. Let's close our previous figure and create a new figure\n",
    "plt.close()\n",
    "plt.figure()\n",
    "\n",
    "# Now let's bring in a set of datapoints. Here I'm going to create the set using numpy distributions for my\n",
    "# y values. First, I'll pull in some exponential values, and I'll sort them from lowest to highest\n",
    "y1=sorted(np.random.exponential(size=100))\n",
    "\n",
    "# Then we can use the poisson distribution, again I'll sort\n",
    "y2=sorted(np.random.poisson(size=100))\n",
    "\n",
    "# The x values will be the same for both of the plots, just a set of linearly increasing values\n",
    "x=np.arange(100)\n",
    "\n",
    "# Now we'll just try and plot them\n",
    "plt.plot(x,y1)\n",
    "plt.plot(x,y2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See? Very easy with matplotlib, it's going to try and plot things automatically as a line plot unless you\n",
    "# tell it otherwise. Want to turn this into a scatter plot instead? Then you can just add a marker type as\n",
    "# the third parameter on plot\n",
    "plt.cla()\n",
    "plt.plot(x,y1,'.')\n",
    "plt.plot(x,y2,'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at a more realistic example, let's say I wanted to compare the temperature in January and\n",
    "# February of 2018 2019 in Ann Arbor. First we need to get the data, I headed over to the NOAA site and\n",
    "# downloaded it from there https://www.ncdc.noaa.gov\n",
    "\n",
    "# Next we need to bring in the two datasets, let's use pandas\n",
    "df18=pd.read_csv(\"1892728.csv\")\n",
    "df19=pd.read_csv(\"1892713.csv\")\n",
    "df19.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So these are just dataframes from a weather station at the airport. We see there is a bunch of missing data\n",
    "# as well as our TMAX and TMIN for maximum and minimum data. Lets join these dataframes together\n",
    "df=pd.concat([df18, df19])\n",
    "\n",
    "# And let's reset the index, since concat() will use the original indicies which are meaningless now\n",
    "df=df.reset_index()\n",
    "\n",
    "# Now lets pull the year out of the date. You might remember this is actually easy for us to do with the\n",
    "# str.extract function of the dataframe, which takes in a regex, then we can just merge those across\n",
    "df=pd.merge(df,df[\"DATE\"].str.extract(\"(?P<year>.{4}).(?P<month_day>.{5})\"), left_index=True, right_index=True)\n",
    "\n",
    "# Ok, let's now just keep our max and min columns for temperature, as well as our new date info\n",
    "df=df[[\"year\",\"month_day\",\"TMAX\",\"TMIN\"]]\n",
    "\n",
    "# Let's take a look at what we have\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now let's setup our figure. We'll do one year at a time, let's make a new function\n",
    "def plot_temp(year):\n",
    "    # first let's close the existing figure if there is one, since we're using the scripting interface\n",
    "    plt.close()\n",
    "    plt.plot(df.where(df[\"year\"]==year).dropna()[\"TMAX\"], label=\"{} Maximum Temperature\".format(year))\n",
    "    plt.plot(df.where(df[\"year\"]==year).dropna()[\"TMIN\"], label=\"{} Minimum Temperature\".format(year))\n",
    "\n",
    "    # Now let's add a legend\n",
    "    plt.legend(loc=4, frameon=False, title='Legend')\n",
    "\n",
    "    # And some axis labels\n",
    "    plt.ylabel(\"Temperature\")\n",
    "    plt.xlabel(\"Day\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's see what that looks like for 2018\n",
    "plot_temp(\"2018\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not bad! A couple of adjustments. Let's make a few tweaks to the display\n",
    "def plot_temp(year):\n",
    "    # first let's close the existing figure if there is one, since we're using the scripting interface\n",
    "    plt.close()\n",
    "    \n",
    "    # Let's manually create the figure so we can set the size\n",
    "    plt.figure(figsize=(10,6))\n",
    "    \n",
    "    # and we'll still plot the data on it like we did before\n",
    "    plt.plot(df.where(df[\"year\"]==year).dropna()[\"TMAX\"], label=\"{} Maximum Temperature\".format(year))\n",
    "    plt.plot(df.where(df[\"year\"]==year).dropna()[\"TMIN\"], label=\"{} Minimum Temperature\".format(year))\n",
    "\n",
    "    # Now let's give matplotlib some freedom to put the legend wherever it feels appropriate\n",
    "    plt.legend(loc=0, frameon=False, title='Legend') # 0 means \"best\"\n",
    "\n",
    "    # And some axis labels\n",
    "    plt.ylabel(\"Temperature\")\n",
    "    plt.xlabel(\"Day\")\n",
    "    \n",
    "    # As well as a title\n",
    "    plt.title(\"Daily Temperature for {}\".format(year))\n",
    "    \n",
    "    # There's a handy function on the axis which allows us to shade the area between two series of data, this\n",
    "    # will really help us see the size of the daily min/max swing. The general function signature is\n",
    "    # fill_between(x, y1, y2), so to do this we need a list of the x axis values (our day), the minimum val,\n",
    "    # and our maximum value. This is actually pretty easy, since we can just use the dataframe index for our\n",
    "    # x values.\n",
    "    plt.gca().fill_between(df.where(df[\"year\"]==year).dropna().index,\n",
    "                           df.where(df[\"year\"]==year).dropna()[\"TMIN\"],\n",
    "                           df.where(df[\"year\"]==year).dropna()[\"TMAX\"],\n",
    "                           facecolor='blue', alpha=0.25)\n",
    "    \n",
    "    # Now let's render it\n",
    "    plt.show()\n",
    "\n",
    "# Let's give it a try with 2018 and 2019 data\n",
    "plot_temp(\"2018\")\n",
    "plot_temp(\"2019\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nice! Ok, let's touch on one more thing with matplotlib in Jupyter. Remember how we are starting each\n",
    "# notebook telling Jupyter to set_matplotlib_close to False? What happens if we leave it as the default, True?\n",
    "set_matplotlib_close(True)\n",
    "\n",
    "plot_temp(\"2018\")\n",
    "plot_temp(\"2019\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Well, in this case, not much! Everything works well and as expected. But underneath Jupyter has closed\n",
    "# off the figures and they are no longer available for editing. For instance, if we look at the available\n",
    "# fignums we get an empty list\n",
    "plt.get_fignums()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly, this means that the current axis and current figure now no longer exist, so we can't update\n",
    "# the figure, and when we try and get the axis a new plot is created by default\n",
    "plt.gca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can all be a source of frustration if you're iteratively trying to build up the display of a plot,\n",
    "# but the upside is it eliminates the need to call show() and you can plot data in just one line\n",
    "plt.plot(range(0,100), sorted(np.random.exponential(size=100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Something to be aware of as you move forward using matplotlib.\n",
    "\n",
    "# In this video you've been given a brief introduction to using matplotlib for two dimensional data using\n",
    "# scatter plots. We've actually covered a lot - from the methodological showing why you would want to engage\n",
    "# in visual exploration of data, using Anscombe's quartet as an example, down to the brass tacks of how to\n",
    "# engage in this exploration using the matplotlib toolkit.\n",
    "\n",
    "# As you've seen, there are a lot of different parameters you can use with matplotlib to control the way\n",
    "# figures are rendered. To explore this, I highly recommend the docs, or a good reference book."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
